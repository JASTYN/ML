{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RoBERTa base and getting AUROC values of ~0.93 with a 100K downsampled/upsampled data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installs and imports\n",
    "#!conda create -y -n st python pandas tqdm\n",
    "#!conda activate st && conda init bash\n",
    "\n",
    "## for mac\n",
    "#!conda install -y -n st pytorch torchvision torchaudio -c pytorch-nightly\n",
    "\n",
    "## for linux\n",
    "#!conda install -y -n tf pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge\n",
    "#!python3 -m pip install --upgrade transformers simpletransformers wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv2Processor\n",
    "import simpletransformers\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from transformers import RobertaForSequenceClassification\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Results\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Train and Test Datasets\n",
    "\n",
    "df_ham = pd.read_csv('../texts/hamCleanScrubbed.txt', sep='\\t', names=['labels','text']).drop_duplicates()\n",
    "df_spam = pd.read_csv('../texts/spamCleanScrubbed.txt', sep='\\t', names=['labels','text']).drop_duplicates()\n",
    "\n",
    "## Drop header if needed\n",
    "df_ham = df_ham.iloc[1: , :]\n",
    "df_spam = df_spam.iloc[1: , :]\n",
    "\n",
    "print('ham dataset:','\\n',df_ham.head(),'\\n\\n','spam dataset:','\\n',df_spam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert text to string\n",
    "df_ham['labels'] = df_ham['labels'].str.lower()\n",
    "df_spam['labels'] = df_spam['labels'].str.lower()\n",
    "\n",
    "## change ham to 0 and spam to 1\n",
    "df_ham['labels'] = df_ham['labels'].replace({'ham':'0', 'spam':'1'})\n",
    "df_spam['labels'] = df_spam['labels'].replace({'ham':'0', 'spam':'1'})\n",
    "\n",
    "## solve potential int errors\n",
    "df_ham['labels'] = df_ham['labels'].astype(pd.Int64Dtype())\n",
    "df_spam['labels'] = df_spam['labels'].astype(pd.Int64Dtype())\n",
    "\n",
    "df_ham.reset_index(drop=True, inplace=True)\n",
    "df_spam.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## confirm there's no ham in spam and vice versa\n",
    "df_ham = df_ham[df_ham['labels'] == 0]\n",
    "df_spam = df_spam[df_spam['labels'] == 1]\n",
    "\n",
    "## Resample data\n",
    "from sklearn.utils import resample\n",
    "## Downsample majority class\n",
    "df_ham_downsampled = resample(df_ham, \n",
    "                                replace=False,   ##replace=False when downsampling, True when upsampling\n",
    "                                n_samples=1000)\n",
    "#Upsample minority class\n",
    "df_spam_upsampled = resample(df_spam, \n",
    "                                replace=True,     \n",
    "                                n_samples=1000)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_up_down_sampled = pd.concat([df_ham_downsampled, df_spam_upsampled]).drop_duplicates()\n",
    "\n",
    "## create train/test split\n",
    "train = np.random.rand(len(df_up_down_sampled)) < 0.75\n",
    "df_train = df_up_down_sampled[train]\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train.loc[:, 'id'] = df_train.index + 1\n",
    "df_train['id'] = df_train['id'].astype(pd.Int64Dtype())\n",
    "df_train = df_train[['id','text','labels']]\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "\n",
    "df_test = df_up_down_sampled[~train]\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_test.loc[:,'id'] = len(df_train.index) + df_test.index + 1\n",
    "df_test['id'] = df_test.loc[:,'id'].astype(pd.Int64Dtype())\n",
    "df_test = df_test[['id','text','labels']]\n",
    "df_test.to_csv('test.csv', index=False)\n",
    "\n",
    "## print train/test data sizes\n",
    "print(\"training rows: \",len(df_train.index))\n",
    "print(\"testing rows: \",len(df_smalltest.index))\n",
    "\n",
    "## drop individual tables to free memory\n",
    "del [[df_ham,df_spam,df_ham_downsampled,df_spam_upsampled,df_up_down_sampled]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop ID columns for training/testing\n",
    "df_train.drop(columns = 'id')\n",
    "df_test.drop(columns = 'id')\n",
    "print(df_train.head(),df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check dataframe type for model\n",
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set and create the classification model we want to use\n",
    "\n",
    "model_args = ClassificationArgs()\n",
    "model_args.num_train_epochs = 1\n",
    "model_args.learning_rate = 2e-5\n",
    "model_args.train_batch_size = 16\n",
    "model_args.eval_batch_size = 16\n",
    "model_args.manual_seed = 42\n",
    "model_args.optimized = \"AdamW\"\n",
    "model_args.adam_epsilon = 1e-8\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "\n",
    "#model = ClassificationModel('roberta', 'mariagrandury/roberta-base-finetuned-sms-spam-detection', num_labels=2, weight=[1 , len(df_ham) / len(df_spam_upsampled)], use_cuda=True, args=model_args)\n",
    "model = ClassificationModel('roberta', 'mariagrandury/roberta-base-finetuned-sms-spam-detection', num_labels=2, weight=[1 , 1], args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train the classification model using training data\n",
    "model.train_model(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our trained model was able to produce an accuracy of 99.3%. It accurately identified 656 spam messages, accurately identified 4311 non-spam messages, falsely identified 16 messages as spam, and 17 messages as non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df_test, acc=sklearn.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make Predictions on Test Data and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the model on test data\n",
    "print(model.config.id2label)\n",
    "\n",
    "predictions, raw_outputs = model.predict(df_test['text'].astype(str).values.tolist())\n",
    "\n",
    "print(predictions, raw_outputs)\n",
    "\n",
    "from scipy.special import softmax\n",
    "probabilities = softmax(raw_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Predictions\n",
    "preds = pd.DataFrame({'id': df_test.index, 'predicted': predictions})\n",
    "preds.head()\n",
    "preds.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
